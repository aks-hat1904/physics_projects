# -*- coding: utf-8 -*-
"""Galaxy_Morphology_Predictor_CNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Z_Fxgdqe1txh5DzwgzS0HzzQHVXKi893
"""

#importing important packages and libraries
import numpy as np
import pandas as pd
import torch
from torch import nn
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from PIL import Image
import os

'''the data used in this model can be found here
https://www.kaggle.com/competitions/galaxy-zoo-the-galaxy-challenge/data'''

!unzip -q /content/training_solutions_rev1.zip

df = pd.read_csv('/content/training_solutions_rev1.csv')

df_train, df_test = train_test_split(df, test_size=.2)
df_train.shape, df_test.shape

#performing EDA
df_train.head(10)

!unzip -q /content/images_training_rev1.zip

trainPath = '/content/images_training_rev1'

import random
#creating a function to plot galaxies from the dataset randomly
def plot_random_galaxy(path, sample=5):
    random_image = random.sample(os.listdir(path), sample)

    plt.figure(figsize=(16,5))
    for i in range(sample):
        plt.subplot(1,sample,i+1)

        img_path = os.path.join(path, random_image[i])
        img = Image.open(img_path)  # Using Pillow to open image

        # Converting PIL Image to numpy array
        img_array = np.array(img)

        plt.imshow(img_array)
        plt.title(f'Class: {random_image[i]}\nShape: {img_array.shape}')
        plt.axis(False)

plot_random_galaxy(trainPath)

import torch
from skimage.transform import resize
from tqdm import tqdm
import matplotlib.pyplot as plt

ORIG_SHAPE = (424,424)
CROP_SIZE = (256,256)
IMG_SHAPE = (64,64)

#creating function to crop and resize images

def get_image(path, x1, y1, shape, crop_size):
    x = plt.imread(path)
    x = x[x1:x1+crop_size[0], y1:y1+crop_size[1]]
    x = resize(x, shape)
    x = x/255.
    # Converting to PyTorch tensor and add channel dimension if needed
    x = torch.from_numpy(x).float()
    # If grayscale, add channel dimension
    if x.ndim == 2:
        x = x.unsqueeze(0)
    # If RGB, transpose to ensure channel-first format
    elif x.ndim == 3 and x.shape[2] in [3, 4]:
        x = x.permute(2, 0, 1)
    return x

#getting all the images from the dataset and converting them to pytorch tensors for data analysis

def get_all_images(dataframe, shape=IMG_SHAPE, crop_size=CROP_SIZE):
    x1 = (ORIG_SHAPE[0]-CROP_SIZE[0])//2
    y1 = (ORIG_SHAPE[1]-CROP_SIZE[1])//2

    sel = dataframe.values
    ids = sel[:,0].astype(int).astype(str)
    y_batch = sel[:,1:]

    x_batch = []
    for i in tqdm(ids):
        x = get_image('/content/images_training_rev1/'+i+'.jpg', x1,y1, shape=shape, crop_size=crop_size)
        x_batch.append(x)

    # Converting list of tensors to a single tensor
    x_batch = torch.stack(x_batch)

    # Convert labels to tensor
    y_batch = torch.tensor(y_batch).float()

    return x_batch, y_batch

X_train, y_train = get_all_images(df_train)
X_test, y_test = get_all_images(df_test)

X_train.shape

X_train[0]

y_train.shape

#there are 49262 images and there are 37 different labels
y_train[0]

#now we will build the model for classification
class Morphology_Predictor(nn.Module):
  def __init__(self,
               input_shape: int,
               output_shape: int):
    super().__init__()
    self.conv_block_1 = nn.Sequential(
        nn.Conv2d(in_channels=input_shape,
                  out_channels=512, kernel_size=3, padding=1),
        nn.Conv2d(in_channels=512,
                  out_channels=256, kernel_size=3, padding=1),
        nn.BatchNorm2d(256),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2)
    )
    self.conv_block_2 = nn.Sequential(
        nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),
        nn.Conv2d(in_channels=256, out_channels=128, kernel_size=3, padding=1),
        nn.BatchNorm2d(128),
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=2, stride=2)
    )
    self.conv_block_3 = nn.Sequential(
        nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),
        nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),
        nn.BatchNorm2d(128),
        nn.ReLU(),
        nn.AdaptiveMaxPool2d(1)
    )
    self.classifier = nn.Sequential(
        nn.Dropout(0.25),
        nn.Linear(128, 128),
        nn.ReLU(),

        nn.Dropout(0.25),
        nn.Linear(128, 128),
        nn.ReLU(),

        nn.Dropout(0.25),
        nn.Linear(128, 128),
        nn.ReLU(),

        nn.Dropout(0.25),
        nn.Linear(in_features=128, out_features=37),
        nn.Sigmoid()

    )

  def forward(self, x):
    x = self.conv_block_1(x)
    #print(x.shape)
    x = self.conv_block_2(x)
    #print(x.shape)
    x = self.conv_block_3(x)
    #print(x.shape)
    x = x.view(x.size(0), -1)
    x = self.classifier(x)

    #print(x.shape)
    return x

#device agnostic code
device = 'cuda' if torch.cuda.is_available() else 'cpu'
device

#creating a model instance on the GPU
model_1 = Morphology_Predictor(input_shape=3, output_shape=37).to(device)

model_1

loss_fn = nn.BCELoss()
optimizer = torch.optim.Adamax(params=model_1.parameters(),
                            lr=0.001)

X_train, y_train = X_train.to(device), y_train.to(device)
X_test, y_test = X_test.to(device), y_test.to(device)
from torch.utils.data import DataLoader
#setting up the batch size hyperparameter
BATCH_SIZE = 128
#turning datasets into iterables(batches)
train_dataloader = DataLoader(
    dataset= list(zip(X_train,y_train)),
    batch_size=BATCH_SIZE,
    shuffle=True

)

test_dataloader = DataLoader(
    dataset= list(zip(X_test,y_test)),
    batch_size=BATCH_SIZE,
    shuffle=False
)

train_dataloader, test_dataloader

#creating a function to time our experiments
from timeit import default_timer as timer
def print_train_time(start: float,
                     end: float,
                     device: torch.device = None):
  total_time = end- start
  print(f'Train time on {device}: {total_time:.3f} seconds')
  return total_time


def multi_label_accuracy(predictions, labels, threshold=0.5):
    """
    Returns:
    - Accuracy as a float
    """
    # Convert predictions and labels to binary using threshold
    binary_predictions = (predictions >= threshold).float()
    binary_labels = (labels >= threshold).float()

    # Calculate true positives, true negatives, false positives, false negatives
    true_positives = torch.sum((binary_predictions == 1) & (binary_labels == 1)).float()
    true_negatives = torch.sum((binary_predictions == 0) & (binary_labels == 0)).float()
    false_positives = torch.sum((binary_predictions == 1) & (binary_labels == 0)).float()
    false_negatives = torch.sum((binary_predictions == 0) & (binary_labels == 1)).float()

    # Calculate accuracy
    accuracy = (true_positives + true_negatives) / (true_positives + true_negatives + false_positives + false_negatives)

    return accuracy.item()

#we need a measure of accuracy for our data where the probabilities are not converted to binary values but are evaluated using proximity of the individual predicted and actual probabilities
def multi_label_mse(predictions, labels):
    """
    Returns:
    - MSE as a float (lower is better)
    """
    return torch.mean((predictions - labels)**2).item()

from tqdm.auto import tqdm

#setting the seed and starting the timer
torch.manual_seed(42)
train_time_start_on_cpu = timer()

epochs = 5

for epoch in tqdm(range(epochs)):
  print(f'Epoch: {epoch}\n--------')
  ###training
  train_loss = 0 #coz we are evaluating the model batchwise so we need a variable for overall loss
  train_mse = 0 #initializing mean squared error
  for batch, (x, y) in enumerate(train_dataloader):
    model_1.train()
    #x, y = x.to(device), y.to(device) #already did this while loading the data in the dataloader
    y_pred = model_1(x)
    loss = loss_fn(y_pred, y)
    mse = multi_label_mse(y_pred, y)
    train_loss += loss
    train_mse += mse
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    if batch % 50 == 0:
      print(f'looked at {batch * len(x)}/{len(train_dataloader.dataset)} samples')

  train_loss /= len(train_dataloader)
  train_mse /= len(train_dataloader)

  test_loss, test_acc, test_mse = 0,0,0
  model_1.eval()
  with torch.inference_mode():
    for x_test, y_test in test_dataloader:
      #x_test, y_test = x_test.to(device), y_test.to(device)
      test_pred = model_1(x_test)
      test_loss += loss_fn(test_pred, y_test)
      test_mse += multi_label_mse(test_pred, y_test)
      test_acc += multi_label_accuracy(test_pred, y_test)
    test_loss /= len(test_dataloader)
    test_acc /= len(test_dataloader)
    test_mse /= len(test_dataloader)

  print(f'Train loss: {train_loss:.5f}, training MSE: {train_mse:.4f}, test loss: {test_loss:.5f}, test acc: {test_acc:.5f}, test MSE: {test_mse:.4f}')

train_time_end_on_cpu = timer()
total_train_time_model_0 = print_train_time(start=train_time_start_on_cpu,
                                             end=train_time_end_on_cpu,
                                             device=str(next(model_1.parameters()).device))

